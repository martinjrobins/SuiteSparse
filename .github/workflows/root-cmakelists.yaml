# Build SuiteSparse using the root CMakeLists.txt

name: root-cmakelists

on:
  workflow_dispatch:
  push:
    branches-ignore:
      - '**/dev2'
  pull_request:

concurrency: ci-root-cmakelists-${{ github.ref }}

jobs:

  ubuntu:
    # For available GitHub-hosted runners, see:
    # https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners
    runs-on: ubuntu-latest

    name: ubuntu (${{ matrix.compiler }} ${{ matrix.cuda }} CUDA)

    strategy:
      # Allow other runners in the matrix to continue if some fail
      fail-fast: false

      matrix:
        compiler: [gcc, clang]
        cuda: [with, without]
        include:
          - compiler: gcc
            compiler-pkgs: "g++ gcc"
            cc: "gcc"
            cxx: "g++"
          - compiler: clang
            compiler-pkgs: "clang libomp-dev"
            cc: "clang"
            cxx: "clang++"
          # Clang seems to generally require less cache size (smaller object files?).
          - compiler: gcc
            ccache-max: 600M
          - compiler: clang
            ccache-max: 500M
          - cuda: with
            cuda-pkgs: "nvidia-cuda-dev nvidia-cuda-toolkit"
            cuda-cmake-flags:
              -DENABLE_CUDA=ON
              -DCUDAToolkit_INCLUDE_DIR="/usr/include"
              -DCMAKE_CUDA_COMPILER_LAUNCHER="ccache"

    env:
      CC: ${{ matrix.cc }}
      CXX: ${{ matrix.cxx }}

    steps:
      - name: checkout repository
        uses: actions/checkout@v3

      - name: install dependencies
        env:
          COMPILER_PKGS: ${{ matrix.compiler-pkgs }}
          CUDA_PKGS: ${{ matrix.cuda-pkgs }}
        run: |
          sudo apt -qq update
          sudo apt install -y ${COMPILER_PKGS} autoconf automake ccache cmake \
            dvipng gfortran libgmp-dev liblapack-dev libmpfr-dev \
            libopenblas-dev ${CUDA_PKGS}

      - name: prepare ccache
        # create key with human readable timestamp
        # used in action/cache/restore and action/cache/save steps
        id: ccache-prepare
        run: |
          echo "key=ccache:ubuntu:root:${{ matrix.compiler }}:${{ matrix.cuda }}:${{ github.ref }}:$(date +"%Y-%m-%d_%H-%M-%S"):${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: restore ccache
        # setup the GitHub cache used to maintain the ccache from one job to the next
        uses: actions/cache/restore@v3
        with:
          path: ~/.ccache
          key: ${{ steps.ccache-prepare.outputs.key }}
          # Prefer caches from the same branch. Fall back to caches from the dev branch.
          restore-keys: |
            ccache:ubuntu:root:${{ matrix.compiler }}:${{ matrix.cuda }}:${{ github.ref }}
            ccache:ubuntu:root:${{ matrix.compiler }}:${{ matrix.cuda }}

      - name: create empty libraries
        # This is to work around a bug in nvlink.
        # See: https://forums.developer.nvidia.com/t/nvlink-fatal-could-not-open-input-file-when-linking-with-empty-static-library/208517
        if: matrix.cuda == 'with'
        run: |
          touch empty.c
          gcc -fPIC -c empty.c -oempty.o
          ar rcsv libdl.a empty.o
          ar rcsv librt.a empty.o
          ar rcsv libpthread.a empty.o
          # overwrite system libraries with "valid" empty libraries
          sudo mv ./libdl.a /usr/lib/x86_64-linux-gnu/libdl.a
          sudo mv ./librt.a /usr/lib/x86_64-linux-gnu/librt.a
          sudo mv ./libpthread.a /usr/lib/x86_64-linux-gnu/libpthread.a

      - name: configure ccache
        env:
          CCACHE_MAX: ${{ matrix.ccache-max }}
        run: |
          test -d ~/.ccache || mkdir ~/.ccache
          echo "max_size = $CCACHE_MAX" >> ~/.ccache/ccache.conf
          echo "compression = true" >> ~/.ccache/ccache.conf
          ccache -s
          echo "/usr/lib/ccache" >> $GITHUB_PATH

      - name: build libraries
        run: |
          printf "::group::   \033[0;32m==>\033[0m Configuring\n"
          mkdir -p ${GITHUB_WORKSPACE}/build && cd ${GITHUB_WORKSPACE}/build
          cmake -DCMAKE_BUILD_TYPE="Release" \
                -DCMAKE_INSTALL_PREFIX=".." \
                -DCMAKE_C_COMPILER_LAUNCHER="ccache" \
                -DCMAKE_CXX_COMPILER_LAUNCHER="ccache" \
                -DCMAKE_Fortran_COMPILER_LAUNCHER="ccache" \
                -DBLA_VENDOR="OpenBLAS" \
                ${{ matrix.cuda-cmake-flags }} \
                ..
          echo "::endgroup::"
          printf "::group::   \033[0;32m==>\033[0m Building\n"
          cmake --build .
          echo "::endgroup::"

      - name: build demos
        run: |
          printf "::group::   \033[0;32m==>\033[0m Configuring for demos\n"
          cd ${GITHUB_WORKSPACE}/build
          cmake -DDEMO=ON ..
          echo "::endgroup::"
          printf "::group::   \033[0;32m==>\033[0m Building demos\n"
          cd ${GITHUB_WORKSPACE}/build
          cmake --build .
          echo "::endgroup::"
          # FIXME: How to run the demos without Makefile?

      - name: ccache status
        continue-on-error: true
        run: ccache -s

      - name: save ccache
        # Save the cache after we are done (successfully) building.
        # This helps to retain the ccache even if the subsequent steps are failing.
        uses: actions/cache/save@v3
        with:
          path: ~/.ccache
          key: ${{ steps.ccache-prepare.outputs.key }}

      - name: install
        run: |
          printf "\033[0;32m==>\033[0m Installing libraries\n"
          cd ${GITHUB_WORKSPACE}/build
          cmake --install .

      - name: build example
        run: |
          cd ${GITHUB_WORKSPACE}/Example/build
          printf "::group::\033[0;32m==>\033[0m Configuring example\n"
          cmake \
            -DBLA_VENDOR="OpenBLAS" \
            ${{ matrix.cuda-cmake-flags }} \
            ..
          echo "::endgroup::"
          printf "::group::\033[0;32m==>\033[0m Building example\n"
          cmake --build .
          echo "::endgroup::"
          printf "::group::\033[0;32m==>\033[0m Executing example\n"
          LD_LIBRARY_PATH=${GITHUB_WORKSPACE}/lib ./my_demo
          echo "::endgroup::"
